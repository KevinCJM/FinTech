# -*- encoding: utf-8 -*-
"""
@File: Markowitz_01_no_limit.py
@Modify Time: 2024/6/4 09:12
@Author: Kevin-Chen
@Descriptions: MCMC + çº¿æ€§è§„åˆ’è°ƒæ•´æƒé‡ + njt
"""

import time
import numpy as np
from Markowitz_01_no_limit import show_random_weights
from numba import njit, prange
from numba import float64, int64
from RandomData_01_rejection_sampling import multi_limit_dict_to_array, is_feasible_njt


@njit(float64[:](float64[:, :], float64[:], float64))
def manual_lst_sq(a, b, regularization=1e-5):
    """
    é€šè¿‡æœ€å°äºŒä¹˜æ³•æ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„çš„è§£ï¼ŒåŒæ—¶å¼•å…¥æ­£åˆ™åŒ–é¡¹ä»¥é¿å…è¿‡æ‹Ÿåˆã€‚

    å‚æ•°:
    a: äºŒç»´æ•°ç»„ï¼Œè¡¨ç¤ºçº¿æ€§æ–¹ç¨‹ç»„çš„ç³»æ•°çŸ©é˜µã€‚
    b: ä¸€ç»´æ•°ç»„ï¼Œè¡¨ç¤ºçº¿æ€§æ–¹ç¨‹ç»„çš„å¸¸æ•°å‘é‡ã€‚
    regularization: æµ®ç‚¹æ•°ï¼Œè¡¨ç¤ºæ­£åˆ™åŒ–é¡¹çš„å¼ºåº¦ã€‚

    è¿”å›:
    ä¸€ç»´æ•°ç»„ï¼Œè¡¨ç¤ºçº¿æ€§æ–¹ç¨‹ç»„çš„è§£å‘é‡ã€‚
    """
    # å°†çŸ©é˜µaè½¬ç½®ï¼Œä¸ºåç»­è®¡ç®—åšå‡†å¤‡
    a_t = a.T
    # è®¡ç®—açš„è½¬ç½®ä¹˜ä»¥aï¼Œå¾—åˆ°ATAçŸ©é˜µ
    ata = np.dot(a_t, a)
    # å¼•å…¥æ­£åˆ™åŒ–é¡¹ï¼Œé˜²æ­¢å¥‡å¼‚çŸ©é˜µï¼ŒçŸ©é˜µåŠ ä¸Šå¯¹è§’çº¿ä¸Šä¸ºregularizationçš„å€¼
    ata = ata + regularization * np.eye(a.shape[1])
    # è®¡ç®—açš„è½¬ç½®ä¹˜ä»¥bï¼Œå¾—åˆ°ATbå‘é‡
    atb = np.dot(a_t, b)
    # è§£å‡ºæ­£åˆ™åŒ–åçš„çº¿æ€§æ–¹ç¨‹ç»„çš„è§£ (np.linalg.solveå‡½æ•°ç”¨äºæ±‚è§£ ğ´ğ‘¥=ğ‘ å½¢å¼çš„æ–¹ç¨‹ç»„)
    correction = np.linalg.solve(ata, atb)
    return correction


@njit(float64[:](float64[:], float64[:, :], int64[:], int64[:], int64[:], float64[:], float64[:], int64))
def primal_dual_interior_point_njt(proposal, the_single_limits, indices_array, start_indices_array, lengths_array,
                                   lower_limits_array, upper_limits_array, max_iter=100):
    num_assets = len(proposal)
    num_constraints = 2 * num_assets + len(lower_limits_array) * 2 + 2

    A = np.zeros((num_constraints, num_assets))
    b = np.zeros(num_constraints)

    idx = 0
    for i in range(num_assets):
        A[idx, i] = 1
        b[idx] = the_single_limits[i][1]
        idx += 1
        A[idx, i] = -1
        b[idx] = -the_single_limits[i][0]
        idx += 1

    for i in range(len(lower_limits_array)):
        start = start_indices_array[i]
        length = lengths_array[i]
        for j in range(length):
            index = indices_array[start + j]
            A[idx, index] = 1
            A[idx + 1, index] = -1
        b[idx] = upper_limits_array[i]
        b[idx + 1] = -lower_limits_array[i]
        idx += 2

    A[idx, :] = 1
    b[idx] = 1
    A[idx + 1, :] = -1
    b[idx + 1] = -1

    x = np.copy(proposal)

    for _ in range(max_iter):
        Ax_b = A.dot(x) - b
        violating = Ax_b > 0

        # å¦‚æœæ²¡æœ‰è¿åä»»ä½•çº¦æŸï¼Œåˆ™ä¼˜åŒ–ç»“æŸ
        if not np.any(violating):
            break

        delta_x = manual_lst_sq(A[violating], Ax_b[violating], regularization=1e-5)
        x -= delta_x

    return x


def randomly_adjust_weights(the_current_weights, step_size, num_adjustments=1):
    """
    éšæœºé€‰æ‹©ä¸€äº›èµ„äº§è¿›è¡Œè°ƒæ•´ã€‚

    :param the_current_weights: numpy array, å½“å‰çš„æƒé‡ã€‚
    :param step_size: float, è°ƒæ•´çš„æ­¥é•¿ã€‚
    :param num_adjustments: int, è¦è°ƒæ•´çš„èµ„äº§æ•°é‡ã€‚
    :return: numpy array, è°ƒæ•´åçš„æƒé‡ã€‚
    """
    indices = np.random.choice(len(the_current_weights), size=num_adjustments, replace=False)
    the_proposal = the_current_weights.copy()
    the_proposal[indices] += np.random.normal(0, step_size, size=num_adjustments)
    the_proposal = np.clip(the_proposal, 0, 1)
    the_proposal /= np.sum(the_proposal)
    return the_proposal


def chang_dict(old_multi_limits, fund_codes_list):
    # æ–°çš„å¤šèµ„äº§é™åˆ¶å­—å…¸
    new_multi_limits = {}

    # éå†åŸå­—å…¸ï¼Œè½¬æ¢é”®
    for key, value in old_multi_limits.items():
        # å°†é”®åˆ†å‰²ä¸ºå•ç‹¬çš„èµ„äº§ä»£ç 
        codes = key.split(',')
        # è·å–æ¯ä¸ªèµ„äº§ä»£ç åœ¨ fund_codes åˆ—è¡¨ä¸­çš„ç´¢å¼•
        indices = tuple(fund_codes_list.index(code) for code in codes)
        # åœ¨æ–°å­—å…¸ä¸­è®¾ç½®è½¬æ¢åçš„é”®å’ŒåŸå§‹å€¼
        new_multi_limits[indices] = value
    return new_multi_limits


@njit(float64[:, :](float64[:], float64[:, :], int64[:], int64[:], int64[:], float64[:], float64[:], float64, int64,
                    int64))
def mcmc_lp_sampling(the_current_weights, single_limit_array, indices, start_indices, lengths, lower_limits,
                     upper_limits, the_step_size, num_samples, max_iter):
    num_assets = len(the_current_weights)
    the_final_weight = np.zeros((num_samples, num_assets))  # é¢„å…ˆåˆ†é…ç©ºé—´
    count = 0  # æœ‰æ•ˆæ ·æœ¬è®¡æ•°å™¨
    # new_proposal_array = np.random.dirichlet(np.ones(num_assets), num_samples)

    for i in range(num_samples):
        new_proposal = the_current_weights + np.random.normal(0, the_step_size, num_assets)
        # new_proposal = new_proposal_array[i]

        adjusted_weights = primal_dual_interior_point_njt(new_proposal, single_limit_array, indices,
                                                          start_indices, lengths,
                                                          lower_limits, upper_limits, max_iter)

        # ä¿ç•™æœ‰æ•ˆçš„è°ƒæ•´åæƒé‡
        if adjusted_weights is not None and is_feasible_njt(adjusted_weights, single_limit_array, indices,
                                                            start_indices, lengths, lower_limits, upper_limits):
            the_final_weight[count] = adjusted_weights
            count += 1
        the_current_weights = adjusted_weights

    return the_final_weight[:count]  # è¿”å›æœ‰æ•ˆæ ·æœ¬éƒ¨åˆ†


@njit(float64[:, :](float64[:, :], int64))
def generate_initial_points(single_limit_array, num_points):
    num_assets = single_limit_array.shape[0]
    points = np.zeros((num_points, num_assets))
    # ç”Ÿæˆè¾¹ç•Œç‚¹
    for i in range(num_assets):
        points[i % num_points, i] = single_limit_array[i, 1]  # ä½¿ç”¨æ¯ä¸ªèµ„äº§çš„ä¸Šé™
        if (i + 1) % num_points < num_points:
            points[(i + 1) % num_points, i] = single_limit_array[i, 0]  # ä½¿ç”¨æ¯ä¸ªèµ„äº§çš„ä¸‹é™
    # æ·»åŠ éšæœºç‚¹
    for i in range(num_assets, num_points):
        points[i, :] = np.random.dirichlet(np.ones(num_assets), 1)
    return points


@njit(float64[:, :](
    int64, float64[:, :], int64[:], int64[:], int64[:], float64[:], float64[:],
    float64, int64, int64, int64), parallel=True)
def run_multiple_mcmc_lp_sampling(num_assets, single_limit_array, indices, start_indices, lengths,
                                  lower_limits, upper_limits, the_step_size, num_samples, max_iter, num_runs=10):
    init_weights = generate_initial_points(single_limit_array, num_runs)
    max_possible_samples = num_samples * len(init_weights)  # å‡è®¾æ¯æ¬¡éƒ½ç”Ÿæˆ num_samples ä¸ªæ ·æœ¬
    all_results = np.zeros((max_possible_samples, num_assets))  # é¢„å…ˆåˆ†é…ç©ºé—´

    # for i in prange(num_runs):
    for i in prange(len(init_weights)):
        start_idx = i * num_samples
        result = mcmc_lp_sampling(
            init_weights[i],  # ç¡®ä¿æ¯æ¬¡è°ƒç”¨éƒ½ä½¿ç”¨åˆå§‹æƒé‡çš„å‰¯æœ¬
            single_limit_array,
            indices,
            start_indices,
            lengths,
            lower_limits,
            upper_limits,
            the_step_size,
            num_samples,
            max_iter
        )
        if result.shape[0] > 0:  # ç¡®ä¿ä¸æ·»åŠ ç©ºæ•°ç»„
            # num_result_samples = result.shape[0]
            # all_results[result_count:result_count + num_result_samples, :] = result
            # result_count += num_result_samples
            end_idx = start_idx + result.shape[0]
            all_results[start_idx:end_idx, :] = result

    # è£å‰ªæ•°ç»„ä»¥åŒ¹é…å®é™…ç»“æœæ•°é‡
    # final_results = all_results[:result_count, :]

    # è®¡ç®—æ¯è¡Œçš„æ€»å’Œ
    row_sums = np.sum(all_results, axis=1)
    # ç­›é€‰å‡ºæ€»å’Œä¸ä¸º0çš„è¡Œ
    filtered_results = all_results[row_sums != 0]

    return filtered_results


def filter_weights_by_gini(the_final_weight, threshold=0.4):
    # è®¡ç®—æ¯è¡Œçš„åŸºå°¼ä¸çº¯åº¦
    gini_impurities = 1 - np.sum(the_final_weight ** 2, axis=1)

    # æ‰¾å‡ºåŸºå°¼ä¸çº¯åº¦å¤§äºç­‰äº0.4çš„è¡Œç´¢å¼•
    valid_indices = gini_impurities >= threshold

    # è¿‡æ»¤å‡ºç¬¦åˆæ¡ä»¶çš„æƒé‡ç»„åˆ
    filtered_weights = the_final_weight[valid_indices]

    return filtered_weights


if __name__ == '__main__':
    fund_codes = ['003816.OF', '660107.OF', '519510.OF', '202302.OF', '000013.OF', '000010.OF',
                  '018060.OF', '006011.OF', '012404.OF', '013706.OF',
                  '960033.OF', '019447.OF', '017092.OF', '017091.OF',
                  '019005.OF', '517520.OF', '018543.OF', '159985.OF']
    single_limits = [(0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0),
                     (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0),
                     (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0),
                     (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0)]
    # multi_limits = {"003816.OF,660107.OF,519510.OF,202302.OF,000013.OF,000010.OF": (0.743, 0.743),
    #                 "018060.OF,006011.OF,012404.OF,013706.OF": (0.216, 0.216),
    #                 "960033.OF,019447.OF,017092.OF,017091.OF": (0.009, 0.009),
    #                 "019005.OF,517520.OF,018543.OF,159985.OF": (0.032, 0.032)}
    multi_limits = {"003816.OF,660107.OF,519510.OF,202302.OF,000013.OF,000010.OF": (0.743205, 0.743205),
                    "018060.OF,006011.OF,012404.OF,013706.OF": (0.215744, 0.215744),
                    "960033.OF,019447.OF,017092.OF,017091.OF": (0.009177, 0.009177),
                    "019005.OF,517520.OF,018543.OF,159985.OF": (0.031874, 0.031874)}

    num_of_asset = len(fund_codes)
    single_limits = np.array(single_limits)
    # å­—å…¸è½¬æ¢
    indices_array, start_indices_array, lengths_array, lower_limits_array, upper_limits_array = (
        multi_limit_dict_to_array(multi_limits, fund_codes))

    # åˆ›å»ºä¸€ä¸ªç­‰æƒé‡çš„åˆå§‹æƒé‡, ç”¨äº†çº¿æ€§è§„åˆ’, å‡ºå‘ç‚¹æ— éœ€åœ¨å¯è¡ŒåŸŸå†…, çº¿æ€§è§„åˆ’ä¼šæŠŠä»–æ‹‰åˆ°å¯è¡ŒåŸŸä¸Šçš„
    current_weights = np.array([1 / num_of_asset] * num_of_asset)
    # éšæœºæ¸¸èµ°çš„æ­¥é•¿
    step_size = 0.5
    # é‡‡æ ·æ¬¡æ•°
    num_samples = 10000

    s_t = time.time()

    ''' è®¡ç®—ä¸€æ¬¡ '''
    # current_weights = clip_array(current_weights, single_limits[:, 0], single_limits[:, 1])
    # print(current_weights)
    # final_weight = primal_dual_interior_point_njt(current_weights, single_limits,
    #                                                   indices_array, start_indices_array, lengths_array,
    #                                                   lower_limits_array, upper_limits_array, max_iter=100)

    ''' å•çº¿ç¨‹ '''
    # final_weight = mcmc_lp_sampling(current_weights, single_limits, indices_array,
    #                                 start_indices_array, lengths_array,
    #                                 lower_limits_array, upper_limits_array,
    #                                 the_step_size=step_size, num_samples=num_samples, max_iter=10)

    ''' å¤šçº¿ç¨‹,ç»•å¼€GILé” (æ•ˆæœä¸€èˆ¬) '''
    final_weight = run_multiple_mcmc_lp_sampling(num_of_asset, single_limits, indices_array,
                                                 start_indices_array, lengths_array,
                                                 lower_limits_array, upper_limits_array,
                                                 the_step_size=step_size, num_samples=600, max_iter=10,
                                                 num_runs=num_of_asset)

    ''' æ‰“å°ä¿¡æ¯ '''
    final_weight = np.array(final_weight).round(7)
    print(final_weight)
    unique_final_weight = np.unique(final_weight, axis=0)
    print(unique_final_weight)
    print("å»é™¤é‡å¤å‰çš„æ•°é‡: ", len(final_weight))
    print("å»é™¤é‡å¤åçš„æ•°é‡: ", len(unique_final_weight))
    print("è®¡ç®—è€—æ—¶: ", time.time() - s_t)

    ''' å‰”é™¤ä¸ç¬¦åˆåŸºå°¼ä¸çº¯åº¦çš„æƒé‡ '''
    unique_final_weight = filter_weights_by_gini(unique_final_weight, threshold=0.2)
    print("å»é™¤åŸºå°¼ä¸çº¯åº¦åçš„æ•°é‡: ", len(unique_final_weight))

    ''' ç”»å›¾ '''
    show_random_weights(unique_final_weight, fund_codes)
